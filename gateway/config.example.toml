# Agentic Gateway Configuration

[server]
host = "0.0.0.0"
port = 8080
cors_origins = ["*"]

[llm]
# Provider configurations
[llm.providers.openai]
api_key = "${OPENAI_API_KEY}"
enabled = true

[llm.providers.anthropic]
api_key = "${ANTHROPIC_API_KEY}"
enabled = true

[llm.providers.groq]
api_key = "${GROQ_API_KEY}"
enabled = true

# Model routing
[llm.models.gpt-4]
provider = "openai"
fallbacks = ["anthropic"]
input_cost_per_1k = 0.03
output_cost_per_1k = 0.06

[llm.models.gpt-3.5-turbo]
provider = "openai"
fallbacks = ["groq"]
input_cost_per_1k = 0.0005
output_cost_per_1k = 0.0015

[llm.models.claude-3-opus]
provider = "anthropic"
fallbacks = ["openai"]
input_cost_per_1k = 0.015
output_cost_per_1k = 0.075

[llm.models.llama3-70b]
provider = "groq"
fallbacks = []
input_cost_per_1k = 0.0
output_cost_per_1k = 0.0

[sandbox]
firecracker_path = "/usr/bin/firecracker"
kernel_path = "/var/lib/firecracker/vmlinux"
rootfs_path = "/var/lib/firecracker/rootfs.ext4"

[sandbox.pool]
min_ready = 2
max_total = 10
idle_timeout_seconds = 300

[rate_limit]
enabled = true
requests_per_minute = 60
tokens_per_minute = 100000
tokens_per_day = 1000000
